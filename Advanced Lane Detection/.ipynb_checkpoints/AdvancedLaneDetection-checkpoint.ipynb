{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Advanced Lane Finding\n",
    "## The goals / steps of this project are the following:\n",
    "\n",
    "\n",
    "#### Camera Calibration\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "\n",
    "#### Create Binary Image for Lanes\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "\n",
    "#### Detect Lane\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "\n",
    "#### Output\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Import necessary libraries for this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some help functions\n",
    "def plot_comparison_images(img1,img2,title1='',title2=''):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1,cmap='gray')\n",
    "    ax1.set_title(title1, fontsize=32)\n",
    "    ax2.imshow(img2,cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=32)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "def plot_comparison_images_with_line(img1,img2,src,dst,title1='',title2=''):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1,cmap='gray')\n",
    "    ax1.set_title(title1, fontsize=32)\n",
    "    x1 = [src[0][0],src[1][0],src[2][0],src[3][0],src[0][0]]\n",
    "    y1 = [src[0][1],src[1][1],src[2][1],src[3][1],src[0][1]]\n",
    "    ax1.plot(x1, y1, 'r-',lw=4)\n",
    "    \n",
    "    ax2.imshow(img2,cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=32)\n",
    "    x2 = [dst[0][0],dst[1][0],dst[2][0],dst[3][0],dst[0][0]]\n",
    "    y2 = [dst[0][1],dst[1][1],dst[2][1],dst[3][1],dst[0][1]]\n",
    "    ax2.plot(x2, y2, 'r-',lw=4)\n",
    "#     plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Camera Calibration & Top-Down View of Undistorted Images\n",
    "### 1.1 Preparation: Find corners from chessboard images\n",
    "\n",
    "`cv2.findChessboardCorners()` to find chessboard corners<br />\n",
    "\n",
    "[Camera Calibration 2.4](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html)<br />\n",
    "[Camera Calibration 3.0](https://docs.opencv.org/3.0-beta/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html)\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"materials/points mapping.jpg\" width=\"800\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Images are distorted when taken, need to undistort them before get true features </p> \n",
    " </figcaption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "# sample chessboard images have 6x9 corners\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "# print(objp)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "\n",
    "# Loop through image and get the chessboard corners, if corners found, attach to objpoints and imgpoints\n",
    "images_cannot_be_used = []\n",
    "image_to_show = 12 # Sample to plot\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    origin_img = np.copy(img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    \n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        corner_img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "#         write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "#         cv2.imwrite(write_name, img)\n",
    "#         cv2.imshow('img', img)\n",
    "#         cv2.waitKey(500)\n",
    "    else:\n",
    "        images_cannot_be_used.append(idx)\n",
    "    \n",
    "    # Plot a sample image\n",
    "    if idx == image_to_show:\n",
    "        plot_comparison_images(origin_img, corner_img, 'Original Image', 'Corners Image')\n",
    "\n",
    "print ('Index for the calibration images that cannot be used: ',images_cannot_be_used)\n",
    "# print (objp[0])\n",
    "# print (imgpoints[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Get parameters for undistort imags\n",
    "`cv2.calibrateCamera()` to get the matrix<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on a calibration image the function of undistortion\n",
    "img = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('./result/calibration01_undist.jpg', undist)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open( \"./result/image_calibration.p\", \"wb\" ) )\n",
    "# Visualize undistortion\n",
    "\n",
    "plot_comparison_images(img,undist,'Original Image','Undistorted Image')\n",
    "\n",
    "print (\"Ret: \", ret)\n",
    "print (\"Intrinsic Param: \", mtx)\n",
    "print (\"Extrinsic Param: \", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Undistort a test image\n",
    "[cv2.undistort()](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#void%20undistort(InputArray%20src,%20OutputArray%20dst,%20InputArray%20cameraMatrix,%20InputArray%20distCoeffs,%20InputArray%20newCameraMatrix)) to undistort the matrix<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort the image, function takes RGB color image\n",
    "def undistort(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Load a test image\n",
    "test_img = cv2.imread('./test_images/straight_lines1.jpg')\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(test_image)\n",
    "\n",
    "# Load the parameters from the repository\n",
    "# dist_param = pickle.load( open( \"./result/image_calibration.p\", \"rb\" ) )\n",
    "# mtx = dist_param[\"mtx\"]\n",
    "# dist = dist_param[\"dist\"]\n",
    "# print (mtx, dist)\n",
    "\n",
    "# Plot the comparision images\n",
    "test_img_undist = undistort(test_img, mtx, dist)\n",
    "plot_comparison_images(test_img, test_img_undist, 'Original Image', 'Undistorted Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Pespective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform the pespective transform\n",
    "def warper(img_undist,src,dst):\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    img_size = (img_undist.shape[1], img_undist.shape[0])\n",
    "    warped = cv2.warpPerspective(img_undist, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv\n",
    "\n",
    "\n",
    "# Test the function on a test image\n",
    "test_img = cv2.imread('./test_images/straight_lines1.jpg')\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "test_img_undist = undistort(test_img,mtx,dist)\n",
    "\n",
    "# Should replace by video image size\n",
    "test_img_size = (test_img_undist.shape[1],test_img_undist.shape[0])\n",
    "\n",
    "\n",
    "src = np.float32([(580,455), (705,455), (1084,660), (235,660)])\n",
    "dst = np.float32([(320,0), (test_img_size[0]-320,0), (test_img_size[0]-320,test_img_size[1]), (320,test_img_size[1])])\n",
    "test_img_warp, M, Minv = warper(test_img_undist,src,dst)\n",
    "\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"src\"] = src\n",
    "dist_pickle[\"dst\"] = dst\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open( \"./result/image_calibration.p\", \"wb\" ) )\n",
    "\n",
    "\n",
    "# Plot the comparision images\n",
    "plot_comparison_images_with_line(test_img_undist, test_img_warp,src,dst,'Original Image','Unwarped Image')\n",
    "# plot_comparison_images(test_img_undist, test_img_unwarp,'Original Image','Unwarped Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_image in glob.glob('./test_images/test*.jpg'):\n",
    "    a_img = cv2.imread(test_image)\n",
    "    a_img = cv2.cvtColor(a_img, cv2.COLOR_BGR2RGB)\n",
    "    ud = undistort(a_img,mtx,dist)\n",
    "    w, m, minv = warper(ud,src,dst)\n",
    "    plot_comparison_images_with_line(ud,w,src,dst,'Original Image','Unwarped Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Binary Images for Lane Detection\n",
    "### 2.1 Just visualize images at different color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just visualize images at different color spaces to get a feeling\n",
    "test_img = cv2.imread('./test_images/test5.jpg')\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "test_img_undist = undistort(test_img, mtx, dist)\n",
    "test_img_warp, M, Minv = warper(test_img_undist,src,dst)\n",
    "plt.imshow(test_img_warp)\n",
    "\n",
    "# RGB space\n",
    "test_img_warp_R = test_img_warp[:,:,0]\n",
    "test_img_warp_G = test_img_warp[:,:,1]\n",
    "test_img_warp_B = test_img_warp[:,:,2]\n",
    "\n",
    "test_img_warp_HLS = cv2.cvtColor(test_img_warp, cv2.COLOR_RGB2HLS)\n",
    "test_img_warp_H = test_img_warp_HLS[:,:,0]\n",
    "test_img_warp_L = test_img_warp_HLS[:,:,1]\n",
    "test_img_warp_S = test_img_warp_HLS[:,:,2]\n",
    "\n",
    "test_img_warp_LAB = cv2.cvtColor(test_img_warp, cv2.COLOR_RGB2Lab)\n",
    "test_img_warp_L_2 = test_img_warp_LAB[:,:,0]\n",
    "test_img_warp_A = test_img_warp_LAB[:,:,1]\n",
    "test_img_warp_B_2 = test_img_warp_LAB[:,:,2]\n",
    "\n",
    "f, ax = plt.subplots(3,3, figsize=(16, 12))\n",
    "f.subplots_adjust(hspace = .2, wspace=.001)\n",
    "axis = ax.ravel()\n",
    "axis[0].imshow(test_img_warp_R, cmap='gray')\n",
    "axis[0].set_title('RGB R-channel', fontsize=30)\n",
    "axis[1].imshow(test_img_warp_G, cmap='gray')\n",
    "axis[1].set_title('RGB G-Channel', fontsize=30)\n",
    "axis[2].imshow(test_img_warp_B, cmap='gray')\n",
    "axis[2].set_title('RGB B-channel', fontsize=30)\n",
    "\n",
    "axis[3].imshow(test_img_warp_H, cmap='gray')\n",
    "axis[3].set_title('HLS H-Channel', fontsize=30)\n",
    "axis[4].imshow(test_img_warp_L, cmap='gray')\n",
    "axis[4].set_title('HLS L-channel', fontsize=30)\n",
    "axis[5].imshow(test_img_warp_S, cmap='gray')\n",
    "axis[5].set_title('HLS S-Channel', fontsize=30)\n",
    "\n",
    "axis[6].imshow(test_img_warp_L_2, cmap='gray')\n",
    "axis[6].set_title('LAB L-channel', fontsize=30)\n",
    "axis[7].imshow(test_img_warp_A, cmap='gray')\n",
    "axis[7].set_title('LAB A-Channel', fontsize=30)\n",
    "axis[8].imshow(test_img_warp_B_2, cmap='gray')\n",
    "axis[8].set_title('LAB B-Channel', fontsize=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Applying Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=20, thresh_max=100):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     gray = (cv2.cvtColor(img, cv2.COLOR_RGB2Lab))[:,:,0]\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def mag_thresh(img, sobel_kernel=13, mag_thresh=(20, 93)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_thresh(img, sobel_kernel=13, thresh=(0, 1.02)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Color Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that thresholds the S-channel of HLS\n",
    "def hls_select(img, thresh=(160, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def luv_select(img, thresh=(220, 255)):\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    l_channel = luv[:,:,0]\n",
    "    u_channel = luv[:,:,1]\n",
    "    v_channel = luv[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(l_channel)\n",
    "    binary_output[(l_channel > thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def lab_select(img, thresh=(155, 210)):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    l_channel = lab[:,:,0]\n",
    "    a_channel = lab[:,:,1]\n",
    "    b_channel = lab[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(b_channel)\n",
    "    binary_output[(b_channel > thresh[0]) & (b_channel <= thresh[1])] = 1\n",
    "    return binary_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the parameters from the repository\n",
    "dist_param = pickle.load( open( \"./result/image_calibration.p\", \"rb\" ) )\n",
    "mtx = dist_param[\"mtx\"]\n",
    "dist = dist_param[\"dist\"]\n",
    "src = dist_param[\"src\"]\n",
    "dst = dist_param[\"dst\"]\n",
    "# print (mtx, dist, dst, src)\n",
    "\n",
    "\n",
    "def process_image(img):\n",
    "    # Image should be in RGB format\n",
    "    img_undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img_unwarp, img_M, img_Minv = warper(img_undist,src,dst)\n",
    "    \n",
    "    # Sobel Absolute\n",
    "    img_sobel_abs = abs_sobel_thresh(img_unwarp)\n",
    "    # Sobel Magnitude\n",
    "    img_sobel_mag = mag_thresh(img_unwarp)\n",
    "    # Sobel Direction\n",
    "    img_sobel_dir = dir_thresh(img_unwarp)\n",
    "    \n",
    "    # HLS Color, using S channel\n",
    "    img_hls_s = hls_select(img_unwarp)\n",
    "    # LUV Color, using L channel\n",
    "    img_luv_l = luv_select(img_unwarp)\n",
    "    # LAB Color, using B channel\n",
    "    img_lab_b = lab_select(img_unwarp)\n",
    "    \n",
    "    combined1 = np.zeros_like(img_sobel_abs)\n",
    "    combined1[(img_sobel_mag == 1) & (img_sobel_dir == 1)] = 1\n",
    "    \n",
    "    combined2 = np.zeros_like(img_hls_s)\n",
    "    combined2[(img_luv_l == 1) | (img_lab_b == 1)] = 1\n",
    "    \n",
    "    combined3 = np.zeros_like(combined1)\n",
    "    combined3[(combined1 == 1) | (combined2 == 1)] = 1\n",
    "    return combined2, img_Minv, img_undist\n",
    "\n",
    "# Test all the images\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "\n",
    "    image = cv2.imread(fname)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_processed, imge_Minv, image_undist = process_image(image)\n",
    "    \n",
    "    plot_comparison_images(image, image_processed, fname, 'Processed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Fit Lane with a Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit binary warped image with window sliding and polynomial\n",
    "def polynomial_fit(img_warped):\n",
    "    \n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img_warped[img_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 10\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 80\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 35\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Window slider\n",
    "    window_slider = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        window_slider.append((win_y_low, win_y_high, win_xleft_low, win_xleft_high, win_xright_low, win_xright_high))\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    left_fit, right_fit = (None, None)\n",
    "    # Fit a second order polynomial to each\n",
    "    if len(leftx) != 0:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit, left_lane_inds, right_lane_inds, histogram, window_slider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Image\n",
    "image_try = cv2.imread('./test_images/test4.jpg')\n",
    "image_try = cv2.cvtColor(image_try, cv2.COLOR_BGR2RGB)\n",
    "binary_warped, image_Minv, image_undist = process_image(image_try)\n",
    "plot_comparison_images(image_undist,binary_warped,title1='Undistorted',title2='Binary')\n",
    "\n",
    "left_fit, right_fit, left_lane_inds, right_lane_inds, histogram, window_slider = polynomial_fit(binary_warped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "out_img = np.uint8(np.dstack((binary_warped, binary_warped, binary_warped))*255)\n",
    "for slider in window_slider:\n",
    "    cv2.rectangle(out_img,(slider[2],slider[0]),(slider[3],slider[1]),(0,255,0), 2) \n",
    "    cv2.rectangle(out_img,(slider[4],slider[0]),(slider[5],slider[1]),(0,255,0), 2)\n",
    "\n",
    "# f, (ax1,ax2) = plt.subplots(2, 1, figsize=(16, 24))\n",
    "# # f.tight_layout()\n",
    "# ax1.imshow(out_img)\n",
    "# ax1.set_title('Unwarp Image', fontsize=24)\n",
    "\n",
    "    \n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = binary_warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "plt.figure(figsize = (9,6))\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_fit_with_pre_fit(img_warped, l_fit, r_fit):\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = img_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 80\n",
    "    left_lane_inds = ((nonzerox > (l_fit[0]*(nonzeroy**2) + l_fit[1]*nonzeroy + l_fit[2] - margin)) & \\\n",
    "                      (nonzerox < (l_fit[0]*(nonzeroy**2) + l_fit[1]*nonzeroy + l_fit[2] + margin))) \n",
    "\n",
    "    right_lane_inds = ((nonzerox > (r_fit[0]*(nonzeroy**2) + r_fit[1]*nonzeroy + r_fit[2] - margin)) & \\\n",
    "                       (nonzerox < (r_fit[0]*(nonzeroy**2) + r_fit[1]*nonzeroy + r_fit[2] + margin)))  \n",
    "\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    left_fit, right_fit = (None, None)\n",
    "    # Fit a second order polynomial to each\n",
    "    if len(leftx) != 0:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit, left_lane_inds, right_lane_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process next image\n",
    "image_try_2 = cv2.imread('./test_images/test5.jpg')\n",
    "image_try_2 = cv2.cvtColor(image_try_2, cv2.COLOR_BGR2RGB)\n",
    "binary_warped_2, image_Minv_2, image_undist_2 = process_image(image_try_2)\n",
    "plot_comparison_images(image_undist_2,binary_warped_2,title1='Undistored_2',title2='Binary_2')\n",
    "\n",
    "left_fit2, right_fit2, left_lane_inds2, right_lane_inds2 = polynomial_fit_with_pre_fit(binary_warped_2, left_fit, right_fit )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image to draw on and an image to show the selection window\n",
    "out_img_2 = np.dstack((binary_warped_2, binary_warped_2, binary_warped_2))*255\n",
    "window_img = np.zeros_like(out_img_2)\n",
    "\n",
    "margin = 65\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped_2.shape[0]-1, binary_warped_2.shape[0] )\n",
    "left_fitx = left_fit2[0]*ploty**2 + left_fit2[1]*ploty + left_fit2[2]\n",
    "right_fitx = right_fit2[0]*ploty**2 + right_fit2[1]*ploty + right_fit2[2]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "plt.figure(figsize = (12,9))\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "result = cv2.addWeighted(out_img_2, 1, window_img, 0.3, 0)\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Compute the Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_curvature(img_warped, l_fit, r_fit, l_lane_inds, r_lane_inds):\n",
    "    \n",
    "    # reset these values\n",
    "    left_curverad, right_curverad, car_diviation = 0,0,0\n",
    "    \n",
    "    ploty = np.linspace(0, img_warped.shape[0]-1, img_warped.shape[0])\n",
    "#     left_fitx = l_fit[0]*ploty**2 + l_fit[1]*ploty + l_fit[2]\n",
    "#     right_fitx = r_fit[0]*ploty**2 + r_fit[1]*ploty + r_fit[2]\n",
    "    \n",
    "    nonzero = img_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Left and right lane pixel indices\n",
    "    leftx = nonzerox[l_lane_inds]\n",
    "    lefty = nonzeroy[l_lane_inds] \n",
    "    rightx = nonzerox[r_lane_inds]\n",
    "    righty = nonzeroy[r_lane_inds]\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_curverad = ((1 + (2*l_fit[0]*y_eval + l_fit[1])**2)**1.5) / np.absolute(2*l_fit[0])\n",
    "    right_curverad = ((1 + (2*r_fit[0]*y_eval + r_fit[1])**2)**1.5) / np.absolute(2*r_fit[0])\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    \n",
    "    # Car is in the center of lower y of image\n",
    "    car_position = img_warped.shape[1]/2\n",
    "    left_lane_in_parallel_to_car = l_fit[0]*img_warped.shape[0]**2 + l_fit[1]*img_warped.shape[0] + l_fit[2]\n",
    "    right_lane_in_parallel_to_car = r_fit[0]*img_warped.shape[0]**2 + r_fit[1]*img_warped.shape[0] + r_fit[2]\n",
    "    car_diviation = (car_position-(left_lane_in_parallel_to_car+right_lane_in_parallel_to_car)/2)*xm_per_pix\n",
    "    \n",
    "    return left_curverad, right_curverad, car_diviation\n",
    "    \n",
    "# a,b,c = compute_curvature(binary_warped, left_fit, right_fit, left_lane_inds, right_lane_inds)\n",
    "# print(a,b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Plotting Back onto Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_road(img_warped, img_origin, Minv, l_fit, r_fit):\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(img_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    ploty = np.linspace(0, img_warped.shape[0]-1, img_warped.shape[0])\n",
    "    left_fitx = l_fit[0]*ploty**2 + l_fit[1]*ploty + l_fit[2]\n",
    "    right_fitx = r_fit[0]*ploty**2 + r_fit[1]*ploty + r_fit[2]\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img_warped.shape[1], img_warped.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img_origin, 1, newwarp, 0.3, 0)\n",
    "#     plt.imshow(result)\n",
    "    return result\n",
    "\n",
    "def plot_info(img_origin, curverad, diviation):\n",
    "    img_curvature = np.copy(img_origin)\n",
    "    font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "    text = 'Curvature: ' + '{:04.2f}'.format(curverad) + 'm'\n",
    "    cv2.putText(img_curvature, text, (40,70), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    \n",
    "    which_side = ''\n",
    "    if diviation > 0:\n",
    "        which_side = ' to the right'\n",
    "    elif diviation < 0:\n",
    "        which_side = 'to the left'\n",
    "    abs_diviation = abs(diviation)\n",
    "    text = 'Diviation: ' + '{:04.3f}'.format(abs_diviation) + 'm ' + which_side + ' of center'\n",
    "    cv2.putText(img_curvature, text, (40,120), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    return img_curvature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new image to try\n",
    "image_final = cv2.imread('./test_images/test5.jpg')\n",
    "image_final = cv2.cvtColor(image_final, cv2.COLOR_BGR2RGB)\n",
    "binary_warped_final, image_Minv_final, image_undist_final = process_image( image_final )\n",
    "left_fit_final, right_fit_final, left_lane_inds_final, right_lane_inds_final, histogram_final, window_slider_final = polynomial_fit(binary_warped_final)\n",
    "left_curverad, right_curverad, car_diviation = compute_curvature( binary_warped, left_fit, right_fit, left_lane_inds, right_lane_inds )\n",
    "road_plot_1 = plot_on_road( binary_warped_final, image_undist_final, image_Minv_final, left_fit_final, right_fit_final )\n",
    "road_plot_2 = plot_info( road_plot_1, (left_curverad+right_curverad)/2, car_diviation )\n",
    "plot_comparison_images(image_final, road_plot_2, title1='Undistorted',title2='Road')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Pipeline to Process Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self, n=5, thres=1):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None   \n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        \n",
    "        #polynomial coefficients for the most recent fit, it is a queue\n",
    "        self.mem_size = n\n",
    "        self.current_fit = deque(maxlen=n) #[np.array([False])] \n",
    "        \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        \n",
    "        self.diffs_thres = np.array([thres/1000,thres,thres*100], dtype='float') \n",
    "    \n",
    "    '''\n",
    "    def eval_new_fit(self, new_fit, new_lane_inds, mem_buff=5):\n",
    "        # This basical pass the new fit to output without any filtering\n",
    "        self.detected = True\n",
    "        self.best_fit = new_fit\n",
    "        self.current_fit.append(new_fit)\n",
    "    '''    \n",
    "        \n",
    "    def eval_new_fit(self, new_fit, new_lane_inds, mem_buff=5):\n",
    "        \n",
    "        # Mem_buff is the maximum number of fit we keep in the current_fit queue\n",
    "        \n",
    "        # If no fit lane found\n",
    "        if new_fit is None:\n",
    "            self.detected = False\n",
    "            try:\n",
    "                self.current_fit.popleft()\n",
    "                if self.current_fit:\n",
    "                    self.best_fit = np.average(np.asarray(self.current_fit), axis=0)\n",
    "                else:\n",
    "                    self.best_fit = None\n",
    "            except:\n",
    "                self.best_fit = None\n",
    "            \n",
    "            '''\n",
    "            if len(self.current_fit) >= 2: # If the fit coefficient queue has more than one value\n",
    "                # Update current fit queue by remove the oldest fit\n",
    "                self.current_fit.popleft()\n",
    "                # Best fit is the avearge over the current_fit queue\n",
    "                self.best_fit = np.average(np.asarray(self.current_fit), axis=0)\n",
    "            elif len(self.current_fit) == 2: # If the fit coefficient queue has only one value\n",
    "                self.current_fit.popleft()\n",
    "                self.best_fit = None\n",
    "            else:\n",
    "                self.best_fit = None\n",
    "            '''\n",
    "            \n",
    "        else:\n",
    "            # If new fit does exist\n",
    "            if self.best_fit is not None:\n",
    "                # Calculate change of fit coefficient in percentage, if it exceeds threshold, throw away the new fit\n",
    "                self.diffs = abs(new_fit-self.best_fit) \n",
    "#                 print(new_fit)\n",
    "#                 print(self.best_fit)\n",
    "#                 print(self.diffs)\n",
    "#                 print(self.diffs>self.diffs_thres)\n",
    "            else:\n",
    "                self.diffs = np.array([0,0,0], dtype='float')\n",
    "            print(\"Difference y0,y1,y2: \", self.diffs)\n",
    "            \n",
    "            if self.diffs[0] > self.diffs_thres[0] or \\\n",
    "                self.diffs[1] > self.diffs_thres[1] or \\\n",
    "                self.diffs[2] > self.diffs_thres[2]:\n",
    "                self.detected = False\n",
    "                try:\n",
    "                    self.current_fit.popleft()\n",
    "                    if self.current_fit:\n",
    "                        self.best_fit = np.average(np.asarray(self.current_fit), axis=0)\n",
    "                    else:\n",
    "                        self.best_fit = None\n",
    "                except:\n",
    "                    self.best_fit = None\n",
    "                \n",
    "            else:\n",
    "                self.detected = True\n",
    "                self.px_count = np.count_nonzero(new_lane_inds)\n",
    "                self.current_fit.append(new_fit) # Remember current_fit is a queue with max_length = 5\n",
    "                self.best_fit = np.average(np.asarray(self.current_fit), axis=0)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_final(img):\n",
    "    bin_warped, Minv, img_undist = process_image(img)\n",
    "    \n",
    "    # If lane is not detected in the previous frame, using polynomial_fit() to find lane, otherwise, using the previous line fit information\n",
    "    if (l_lane.detected == False) or (r_lane.detected == False):\n",
    "        l_fit, r_fit, l_lane_inds, r_lane_inds, _a, _b = polynomial_fit(bin_warped)\n",
    "        \n",
    "    else:\n",
    "        l_fit, r_fit, l_lane_inds, r_lane_inds = polynomial_fit_with_pre_fit(bin_warped, l_lane.best_fit, r_lane.best_fit)\n",
    "#         print ('Hist Fit', l_fit, r_fit)\n",
    "    \n",
    "    l_lane.eval_new_fit(l_fit, l_lane_inds)\n",
    "    r_lane.eval_new_fit(r_fit, r_lane_inds)\n",
    "    \n",
    "    print ('Best Fit: ', l_lane.best_fit, r_lane.best_fit)\n",
    "    print ('Queue Size: ', len(l_lane.current_fit), len(r_lane.current_fit) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    if l_lane.best_fit is None or r_lane.best_fit is None:\n",
    "        # If not fit found, display original image\n",
    "        result = np.copy(img_undist)\n",
    "    else:\n",
    "        left_curverad, right_curverad, car_diviation = compute_curvature( bin_warped, l_lane.best_fit, r_lane.best_fit, l_lane_inds, r_lane_inds)\n",
    "        plot_polyfit = plot_on_road( bin_warped, img_undist, Minv, l_lane.best_fit, r_lane.best_fit )\n",
    "        result = plot_info( plot_polyfit, (left_curverad+right_curverad)/2, car_diviation )\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some pre-computed data\n",
    "dist_param = pickle.load( open( \"./result/image_calibration.p\", \"rb\" ) )\n",
    "mtx = dist_param[\"mtx\"]\n",
    "dist = dist_param[\"dist\"]\n",
    "src = dist_param[\"src\"]\n",
    "dst = dist_param[\"dst\"]\n",
    "\n",
    "# Define new lines (lanes), memory_buff_size = 5 by default\n",
    "l_lane = Line()\n",
    "r_lane = Line()\n",
    "\n",
    "video_output = 'test_videos_output/project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\")#.subclip(38,42)\n",
    "\n",
    "# clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "white_clip = clip1.fl_image(process_final)\n",
    "white_clip.write_videofile(video_output, audio=False)\n",
    "# %time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
